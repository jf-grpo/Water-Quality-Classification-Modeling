{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b50ddddc-4170-489b-b88b-6cf45c0f2ed5",
   "metadata": {},
   "source": [
    "# Portfolio Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b7567e-f554-440d-92e1-27915a4beef5",
   "metadata": {},
   "source": [
    "### For this project I will follow the ML (Machine Learning) workflow taught in Codecademy's: \n",
    "#### 'Machine Learning/AI Engineer' career path\n",
    "1. ETL (Extract, Transform and Load) data\n",
    "2. Data Cleaning\n",
    "3. Train-Test-Validation Split\n",
    "4. EDA (Exploratory Data Analysis)\n",
    "5. Feature Engineering (normalization, removing autocorrelations, discretization, etc.)\n",
    "6. Model Selection and Implementation\n",
    "7. Model Evaluation\n",
    "8. Hyperparameter Tuning\n",
    "9. Model Validation\n",
    "10. Build ML pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebdf4c3-2dd7-4492-847f-d46b9da205ab",
   "metadata": {},
   "source": [
    "### Project Scoping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8df32f8-2842-49b8-a61e-9f42080e4aab",
   "metadata": {},
   "source": [
    "#### Goals  \n",
    "- improve my understanding of Machine Learning concepts I've learned through the Codecademy\n",
    "  \"Machine Learning-Engineering\" track by applying them to unfamiliar datasets.\n",
    "- Choose a dataset from kaggle\n",
    "- Import the dataset\n",
    "- Based on dataset choice, decide what to glean (prediction, classification, etc.)\n",
    "- Perform EDA & gain solid understanding of the data\n",
    "- Decide on Machine Learning technique/s\n",
    "- Build the model\n",
    "- Test model performance/score\n",
    "- Publish code to GitHub and Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee80528-2a8c-4f67-b885-59435a3d0ede",
   "metadata": {},
   "source": [
    "#### I decided to use Water Quality (potability) datasets  \n",
    "- I will pursue a 'classification' approach.\n",
    "- Based on the features, is the water safe (potable) of unsafe (not potable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ec72eb-4136-49ba-ba9e-8ec29ab186d6",
   "metadata": {},
   "source": [
    "I will first import the dataset for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d9b05e-0d86-41cc-8798-8b56c9c67303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea74208d-1961-47a3-b4b1-c0d145b90cfd",
   "metadata": {},
   "source": [
    "#### I found two datasets in Kaggle and need to see if they are the exact same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1114b5e3-3943-4c04-b19c-dc559af27753",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('water_potability_AdityaKadiwal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538b92e1-bce3-4c5b-b738-d324c23384d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('water_potability_LaksikaTharmalingam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b019c0-58e0-4121-8169-04fbaf1173e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = pd.merge(df, df2, on=list(df.columns), how='outer', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0737755d-846d-497b-9cb6-434b85e72a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = compare_df[compare_df['_merge'] != 'both']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a875a3-47ac-482d-b4df-0e9da8c475bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(differences) == 0:\n",
    "    print(\"Datasets are identical\")\n",
    "else:\n",
    "    print(\"Data are NOT identical\")\n",
    "#print(\"Rows unique to either df or df2:\")\n",
    "#differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae2a6ce-8efb-4b2b-854c-94538e98a919",
   "metadata": {},
   "source": [
    "#### They are indeed the same. So, I will use the better documented one.  \n",
    "Aditya Kadiwal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e19bc8b-68f3-47b1-9d90-635f99f1a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Head: \\n{df.head()}\\n\",\n",
    "    f'Number of Unique Values: \\n{df.nunique()}\\n',\n",
    "    f'Information: \\n{df.info()}\\n',\n",
    "    f'Describe the data: \\n{df.describe()}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a6b5c-54c5-4791-963a-46f6fc36f48e",
   "metadata": {},
   "source": [
    "### First Dilemma: What to do with rows that have NULL values in columns?  \n",
    "1. Remove any rows that have null values - ```df.dropna()```\n",
    "2. Fill null values with mean of that column - ```df['col'].fillna(df['col'].mean(), inplace=True)```\n",
    "3. Fill null values with the mode if non-numeric - ```df['col'].fillna(df['col'].mode()[0], inplace=True)```\n",
    "4. Fill null values with the mediam of that column - ```df['col'].fillna(df['col'].median(), inplace=True)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e92bae6-eb16-4e56-bbdb-837c3ead0ea2",
   "metadata": {},
   "source": [
    "#### Let's create a dataframe for 1, 2, and 4  \n",
    "I can then run each through the model to see the different results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327208c2-af70-42e1-b3ca-3f85c141fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_null = df.dropna()\n",
    "fillWithMean = df.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "fillWithMedian = df.apply(lambda col: col.fillna(col.median()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e926695-b5cd-482b-abdb-5cec99611d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "myDFs = [remove_null,fillWithMean,fillWithMedian]\n",
    "for x in myDFs:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00353ea-89d6-4b6e-88bf-5df620da3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in myDFs:\n",
    "    print(x.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d07f9-3ef7-4174-a7ee-70dcde314d9d",
   "metadata": {},
   "source": [
    "#### Conclusion of creating the 3 DataFrames:  \n",
    "- ```remove_null``` is only 2011 rows. The smallest dataset.\n",
    "- ```fillWithMean``` is the same size as the original (3276) but I gave more strength to the average.\n",
    "- ```fillWithMedian``` is the same size as the original (3276) but gave more strength the median value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ece5cfa-4433-474d-9721-a4d92ff58762",
   "metadata": {},
   "source": [
    "#### For the remainder of this code I will leverage the 'fillWithMean' Dataset as I anticipate better feature selection and prediction opportunities with more rows of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f63a258-bbd3-4da9-8248-5c42909e7b4d",
   "metadata": {},
   "source": [
    "Notes:   \n",
    "Aside from the Null (NaN) values this is a clean dataset.  \n",
    "With that in mind I will not conduct EDA (Explorotory Data Analysis) beyond the basic methods I've ran in the introduction:  \n",
    "- Unique values\n",
    "- describe()\n",
    "- info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78fbf3-88d0-48eb-819d-bb8cb5a6bf6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
